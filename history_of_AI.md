# 人工智能史

人工智能 (AI) 的历史始于古代，当时充斥着各种神话、故事和传闻，讲述着工匠赋予人工智能或意识的故事。自古至今，对逻辑和形式推理的研究直接促成了 20 世纪 40 年代可编程数字计算机的发明，这是一种基于抽象数学推理的机器。这种装置及其背后的理念启发了科学家们开始探讨构建电子大脑的可能性。

人工智能研究领域始于 1956 年在达特茅斯学院举办的一次研讨会。 研讨会的与会者成为了数十年来人工智能研究的领军人物。他们中的许多人预测，在一代人的时间内，就能出现与人类一样智能的机器。美国政府为此提供了数百万美元的资金，希望能够实现这一愿景。

最终，人们发现，研究人员严重低估了这一壮举的难度。 1974年，詹姆斯·莱特希尔（James Lighthill）的批评和美国国会的压力迫使美国和英国政府停止资助那些没有明确方向的人工智能研究。七年后，日本政府的一项富有远见的举措以及专家系统的成功，重新激发了对人工智能的投资。到20世纪80年代末，该产业已发展成为一个价值数十亿美元的产业。然而，投资者的热情在20世纪90年代逐渐消退，该领域受到媒体的批评，并被业界回避（这一时期被称为“人工智能寒冬”）。尽管如此，研究和资金仍在以其他名义继续增长。

在21世纪初，机器学习被广泛应用于学术界和工业界的各种问题。其成功得益于强大的计算机硬件、海量数据集的收集以及扎实的数学方法的应用。不久之后，深度学习被证明是一项突破性的技术，超越了所有其他方法。 Transformer 架构于 2017 年首次亮相，并被用于开发令人印象深刻的生成式 AI 应用以及其他用例。

2020 年代，人工智能投资蓬勃发展。由 Transformer 架构的发展引发的近期人工智能热潮，推动了 ChatGPT 等大型语言模型 (LLM) 的快速扩展和公开发布。这些模型展现出与人类相似的知识、注意力和创造力特征，并已被应用于各个领域，从而推动了人工智能投资的指数级增长。然而，人们对高级人工智能的潜在风险和伦理影响的担忧也随之出现，引发了关于人工智能未来及其社会影响的争论。

## 神话、虚构和推测的前兆

### 神话与传说

在希腊神话中，塔洛斯是一位青铜铸成的生物，守护着克里特岛。他会向入侵者的船只投掷巨石，并每天绕岛一周。 根据伪阿波罗多罗斯的《图书馆》，赫菲斯托斯在独眼巨人的帮助下打造了塔洛斯，并将这尊自动机械作为礼物赠予米诺斯。 在《阿尔戈英雄纪》中，伊阿宋和阿尔戈英雄们拔掉了塔洛斯脚边的一个塞子，导致他体内重要的脓液流出，最终击败了他。

### 中世纪人造生物的传说

歌德《浮士德》中对侏儒的描绘
在《物性论》中，瑞士炼金术士帕拉塞尔苏斯描述了一种他声称可以制造“人造人”的方法。将“人类的精子”放入马粪中，并在40天后为其注入“人类血液的奥秘”，混合物就会变成一个活生生的婴儿。

最早关于制造傀儡的书面记载出现在13世纪初沃尔姆斯的埃利亚撒·本·犹大的著作中。在中世纪，人们相信，将一张写有任意一位神之名的纸条塞进泥塑人的嘴里，就能使傀儡复活。 与传说中的铜头自动机不同，傀儡无法说话。

“塔克温”（Takwin），即人工创造生命，是伊斯玛仪派炼金术手稿中经常出现的主题，尤其是那些被认为由贾比尔·伊本·哈扬（Jabir ibn Hayyan）撰写的手稿。伊斯兰炼金术士试图通过他们的工作创造出各种各样的生命，从植物到动物。

在约翰·沃尔夫冈·冯·歌德（Johann Wolfgang von Goethe）的《浮士德：悲剧的第二部分》中，一个通过炼金术制造的侏儒，注定要永远活在他被创造的瓶子里，努力想要获得一个完整的人类身体。然而，在这种转变开始时，瓶子破碎了，侏儒也死了。

### 现代小说

*主条目：小说中的人工智能*

到了19世纪，关于人工智能和思维机器的构想成为小说中的热门主题。玛丽·雪莱的《科学怪人》和卡雷尔·恰佩克的《罗素姆万能机器人》（R.U.R.）等著名作品探讨了人工生命的概念。塞缪尔·巴特勒的《机器中的达尔文》和埃德加·爱伦·坡的《梅尔泽尔的棋手》等思辨性散文反映了社会对人工智能机器日益增长的兴趣。人工智能至今仍是科幻小说中的一个常见主题。

### 自动机

*主条目：自动机*

阿尔·贾扎里的可编程自动机（公元 1206 年）
许多文明的工匠都制造了逼真的人形自动机，其中包括偃师、亚历山大的希罗、阿尔·贾扎里、哈伦·拉希德、雅克·德·沃康松、列奥纳多·托雷斯-克维多、皮埃尔·雅克-德罗兹和沃尔夫冈·冯·肯佩伦。

已知最古老的自动机是古埃及和希腊的圣像。 信徒们相信，工匠赋予了这些雕像真实的思想，使其拥有智慧和情感——赫尔墨斯·特里斯墨吉斯忒斯写道：“通过发现神的真实本质，人类能够复制它们。”英国学者亚历山大·内克汉姆（Alexander Neckham）断言，古罗马诗人维吉尔建造了一座带有自动机雕像的宫殿。

在近代早期，这些传说中的自动机被认为拥有神奇的能力，可以回答人们向它们提出的各种问题。据称，中世纪晚期的炼金术士、原始新教徒罗杰·培根（Roger Bacon）曾捏造了一个铜头，并编造了一个关于他曾是巫师的传说。 这些传说与北欧神话中关于密米尔之头的传说相似。根据传说，密米尔以其智慧而闻名，并在阿萨神族-华纳神族战争中被斩首。据说奥丁用草药“防腐”了密米尔的头颅，并对着它念咒语，使密米尔的头颅仍然能够向奥丁诉说智慧。奥丁随后将头颅放在身边，以便征求他的建议。

### 形式推理

人工智能基于人类思维过程可以机械化的假设。对机械推理（或“形式推理”）的研究历史悠久。早在公元前一千年，中国、印度和希腊哲学家就已发展出结构化的形式推理方法。这些思想经过几个世纪的发展，得到了亚里士多德（对三段论进行了形式分析）、欧几里得（其《几何原本》是形式推理的典范）、花拉子密（发展了代数，并将“算法”一词命名为他的名字）以及奥卡姆的威廉和邓斯·司各特等欧洲经院哲学家 的进一步发展。

西班牙哲学家拉蒙·柳尔（Ramon Llull，1232-1315）发明了几种逻辑机器，致力于通过逻辑手段产生知识； 柳尔将他的机器描述为机械实体，它们可以通过简单的逻辑运算将基本且不可否认的真理结合起来，这些真理由机器通过机械意义产生，从而产生所有可能的知识。 柳尔的工作对戈特弗里德·莱布尼茨产生了巨大的影响，后者重新发展了他的思想。

戈特弗里德·莱布尼茨推测人类理性可以简化为机械计算。
在17世纪，莱布尼茨、托马斯·霍布斯和勒内·笛卡尔探索了所有理性思维都可以像代数或几何一样系统化的可能性。 霍布斯在《利维坦》中写道：“理性……不过是计算，也就是加减。”莱布尼茨设想了一种通用的推理语言，即“普遍性”（characterica universalis），它将论证简化为计算，这样“两位哲学家之间就无需争论，就像两位会计师之间无需争论一样。因为他们只需拿起铅笔，在石板上，互相说一声（如果愿意，可以请一位朋友作证）：‘我们来计算一下’就行了。” 这些哲学家开始阐明物理符号系统假说，这将指导人工智能研究。

数理逻辑的研究提供了使人工智能看似可行的关键突破。布尔的《思维定律》和弗雷格的《概念文字》等著作奠定了基础。在弗雷格体系的基础上，罗素和怀特海于1913年在其杰作《数学原理》中对数学基础进行了形式化处理。受罗素成功的启发，大卫·希尔伯特向20世纪20年代和30年代的数学家们提出了一个挑战，让他们回答这个基本问题：“所有的数学推理都能形式化吗？” 哥德尔的不完备性证明、图灵机和丘奇的λ演算[a]回答了他的问题。

美国陆军拍摄的摩尔电气工程学院的ENIAC照片
他们的答案在两个方面令人惊讶。首先，他们证明了数理逻辑所能实现的功能实际上是有限的。其次（这对人工智能来说更为重要），他们的工作表明，在这些限制之内，任何形式的数学推理都可以机械化。丘奇-图灵论题暗示，一个机械装置，通过对 0 和 1 这样简单的符号进行混洗，可以模仿任何可以想象的数学推理过程。 关键的洞见是图灵机——一种简单的理论构造，捕捉到了抽象符号操作的本质。 这项发明激发了少数科学家开始讨论思考机器的可能性。

### 计算机科学

*主条目：计算机硬件史和计算机科学史*

古代和历史上，许多人都设计或制造过计算机器，其中包括戈特弗里德·莱布尼茨、约瑟夫·玛丽·雅卡尔、查尔斯·巴贝奇、珀西·卢德盖特、莱昂纳多·托雷斯·克维多、万尼瓦尔·布什等人。艾达·洛夫莱斯推测巴贝奇的机器是“一台思考或……推理机器”，但她警告说，“最好警惕人们对该机器能力的夸大其词”。

第一批现代计算机是第二次世界大战期间的巨型机器（例如康拉德·楚泽的Z3、艾伦·图灵的希思·罗宾逊和巨像、阿塔纳索夫和贝里的ABC，以及宾夕法尼亚大学的ENIAC）。 ENIAC 基于艾伦·图灵奠定的理论基础，由约翰·冯·诺依曼开发，并被证明是最具影响力的。

## 人工智能的诞生（1941-1956）

IBM 702：第一代人工智能研究人员使用的计算机。
最早对思维机器的研究受到20世纪30年代末、40年代和50年代初盛行的一系列思想的启发。当时的神经病学研究表明，大脑是一个由神经元组成的电网络，发出“全有或全无”的脉冲。诺伯特·维纳的控制论描述了电网络的控制和稳定性。克劳德·香农的信息论描述了数字信号（即“全有或全无”的信号）。艾伦·图灵的计算理论表明，任何形式的计算都可以用数字方式描述。这些思想之间的密切联系表明，构建一个“电子大脑”是可能的。

20 世纪 40 年代和 50 年代，来自数学、心理学、工程学、经济学和政治学等不同领域的少数科学家探索了几个对后来的人工智能研究至关重要的研究方向。 艾伦·图灵是第一批认真研究“机器智能”理论可能性的人之一。 “人工智能研究”领域于 1956 年作为一门学科成立。

### 图灵测试

*主条目：图灵测试*

1950年，图灵发表了一篇具有里程碑意义的论文《计算机器与智能》，他在文中推测了创造能够思考的机器的可能性。[b] 在论文中，他指出“思考”难以定义，并设计了著名的图灵测试：如果一台机器能够（通过电传打字机）进行的对话与人类对话难以区分，那么就可以合理地说该机器正在“思考”。 这个简化版本的问题是图灵能够令人信服地论证“思考机器”至少是合理的，并且该论文回答了对该命题的所有最常见的反对意见。 图灵测试是人工智能哲学中第一个严肃的提议。

### 神经科学与赫布理论

唐纳德·赫布是一位加拿大心理学家，他的研究为现代神经科学奠定了基础，尤其是在理解学习、记忆和神经可塑性方面。他最具影响力的著作《行为的组织》（1949年）提出了赫布学习的概念，通常被概括为“一起激发的细胞，彼此连接”。

赫布在20世纪40年代初开始构思这本书的基本思想，尤其是在1942年至1947年他在耶基斯灵长类生物学实验室工作期间。他在1944年6月至1945年3月期间做了大量笔记，并于1946年将完整的草稿寄给了他的导师卡尔·拉什利。《行为的组织》手稿直到1949年才出版。这一延迟是由于多种因素造成的，包括第二次世界大战和学术重心的转变。当这本书出版时，他的几位同行已经发表了相关观点，这使得赫布的研究乍一看似乎缺乏开创性。然而，他对心理学和神经生理学原理的综合运用，成为了神经科学和机器学习的基石。

### 人工神经网络

沃尔特·皮茨和沃伦·麦卡洛克于1943年分析了理想化的人工神经元网络，并展示了它们如何执行简单的逻辑功能。他们首次描述了后来研究人员称之为神经网络的东西。 这篇论文受到了图灵1936年论文《论可计算数》的影响，该论文使用了类似的双状态布尔“神经元”，但首次将其应用于神经元功能。 受皮茨和麦卡洛克启发的学生之一是当时24岁的研究生马文·明斯基。1951年，明斯基和迪安·埃德蒙兹建造了第一台神经网络机器——SNARC。 明斯基后来成为人工智能领域最重要的领导者和创新者之一。

### 控制论机器人

W. Grey Walter 的海龟机器人和约翰·霍普金斯大学的“野兽”机器人等实验性机器人于 20 世纪 50 年代问世。这些机器没有使用计算机、数字电子设备或符号推理，而是完全由模拟电路控制。

### 游戏人工智能

1951 年，克里斯托弗·斯特雷奇 (Christopher Strachey) 使用曼彻斯特大学的 Ferranti Mark 1 机器编写了一个跳棋程序，迪特里希·普林茨 (Dietrich Prinz) 也编写了一个国际象棋程序。亚瑟·塞缪尔 (Arthur Samuel) 的跳棋程序，也就是他 1959 年论文《使用跳棋游戏进行机器学习的一些研究》的主题，最终达到了足以挑战一位受人尊敬的业余爱好者的水平。 塞缪尔的程序是后来被称为机器学习的早期应用之一。 在整个人工智能发展史上，游戏人工智能一直被用作衡量人工智能进步的标准。

### 符号推理与逻辑理论家

*主条目：逻辑理论家*

赫伯特·西蒙（左）在约1958年的一场国际象棋比赛中对阵艾伦·纽厄尔
20世纪50年代中期，当数字计算机问世时，一些科学家本能地意识到，能够操纵数字的机器也能操纵符号，而符号的操纵很可能是人类思维的本质。这是一种创造思维机器的新方法。

1955年，艾伦·纽厄尔和未来的诺贝尔奖得主赫伯特·A·西蒙在J·C·肖的帮助下创建了“逻辑理论家”。该程序最终证明了罗素和怀特海《数学原理》中前52条定理中的38条，并为其中一些定理找到了新的、更优雅的证明。西蒙称他们“解决了古老的身心问题，解释了一个由物质构成的系统如何拥有心灵的属性”。[c] 他们提出的符号推理范式，在90年代中期之前一直主导着人工智能的研究和资金，并激发了认知革命。

### 达特茅斯研讨会

*主条目：达特茅斯研讨会*

1956年的达特茅斯研讨会是标志着人工智能正式成为一门学科的关键事件。 该研讨会由马文·明斯基和约翰·麦卡锡组织，并得到了IBM两位资深科学家克劳德·香农和内森·罗切斯特的支持。会议提案指出，他们旨在验证以下断言：“学习的每个方面或智能的任何其他特征都可以被精确地描述，从而使得机器能够对其进行模拟”。[d] 约翰·麦卡锡在研讨会上提出了“人工智能”一词。[e] 与会者包括雷·所罗门诺夫、奥利弗·塞尔弗里奇、特伦查德·莫尔、亚瑟·塞缪尔、艾伦·纽厄尔和赫伯特·A·西蒙，他们都在人工智能研究的最初几十年中创建了重要的程序。[f] 在研讨会上，纽厄尔和西蒙首次推出了“逻辑理论家”。 这次研讨会标志着人工智能获得了其名称、使命、首次重大成功和关键参与者，并被广泛认为是人工智能的诞生。[g]

### 认知革命

*主条目：认知革命*

1956年秋，纽厄尔和西蒙还在麻省理工学院（MIT）信息理论特别兴趣小组的一次会议上介绍了“逻辑理论家”。在同一次会议上，诺姆·乔姆斯基讨论了他的生成语法，乔治·米勒则介绍了他具有里程碑意义的论文《神奇的数字七，加或减二》。米勒写道：“我离开研讨会时，带着一种直觉而非理性的信念：实验心理学、理论语言学和认知过程的计算机模拟都是一个更大整体的碎片。”

这次会议开启了“认知革命”——一场心理学、哲学、计算机科学和神经科学跨学科范式的转变。它启发了符号人工智能、生成语言学、认知科学、认知心理学、认知神经科学以及计算主义和功能主义等哲学流派的诞生。所有这些领域都使用相关的工具来模拟心智，并且一个领域的研究成果与其他领域息息相关。

认知方法使研究人员能够思考“心理对象”，例如想法、计划、目标、事实或记忆，这些对象通常使用功能网络中的高级符号进行分析。这些对象被早期的行为主义等范式视为“不可观察”而被禁止。[h] 符号心理对象将成为未来几十年人工智能研究和资助的主要焦点。

## 早期成功（1956-1974）

达特茅斯研讨会之后几年开发的程序对大多数人来说简直是“惊人的”：[i] 计算机能够解决代数应用题、证明几何定理，甚至学会说英语。当时几乎没有人相信机器能够拥有如此“智能”的行为。 研究人员在私下和公开场合表达了强烈的乐观态度，预测完全智能的机器将在不到20年内被制造出来。 国防高级研究计划局（DARPA，当时称为“ARPA”）等政府机构向该领域投入了大量资金。 20世纪50年代末和60年代初，许多英国和美国大学建立了人工智能实验室。

### 方法

20世纪50年代末和60年代出现了许多成功的项目和新的研究方向。其中最具影响力的包括：

#### 推理、规划和问题求解即搜索

许多早期的人工智能程序使用相同的基本算法。为了实现某个目标（例如赢得游戏或证明定理），它们会一步步地（通过移动或推导）朝着目标前进，就像在迷宫中搜索一样，一旦遇到死胡同就回溯。 主要的困难在于，对于许多问题来说，穿过“迷宫”的可能路径数量是天文数字（这种情况被称为“组合爆炸”）。研究人员会使用启发式方法来缩小搜索空间，排除那些不太可能找到解决方案的路径。

Newell 和 Simon 试图在一个名为“通用问题求解器”的程序中捕捉该算法的通用版本。其他“搜索”程序能够完成令人印象深刻的任务，例如解决几何和代数问题，例如赫伯特·格伦特 (Herbert Gelernter) 的几何定理证明器 (1958) 和明斯基的学生詹姆斯·斯拉格尔 (James Slagle) 于 1961 年编写的符号自动积分器 (SAINT)。 其他程序则通过搜索目标和子目标来规划行动，例如斯坦福大学开发的用于控制机器人 Shakey 行为的 STRIPS 系统。

#### 自然语言

语义网络示例
人工智能研究的一个重要目标是让计算机能够使用英语等自然语言进行交流。早期的成功案例是丹尼尔·鲍勃罗 (Daniel Bobrow) 的程序 STUDENT，它可以解决高中代数应用题。

语义网络将概念（例如“房子”、“门”）表示为节点，将概念之间的关系表示为节点之间的链接（例如“has-a”）。第一个使用语义网络的人工智能程序是由 Ross Quillian 编写的，其中最成功（也是最具争议的）的版本是 Roger Schank 的概念依赖理论。

Joseph Weizenbaum 的 ELIZA 可以进行非常逼真的对话，以至于用户有时会误以为他们是在与人交流，而不是与计算机程序交流（参见 ELIZA 效应）。但实际上，ELIZA 只是给出了预设的回复，或者只是重复了对方说的话，并用一些语法规则重新表述。ELIZA 是第一个聊天机器人。

#### 微观世界

20 世纪 60 年代末，麻省理工学院人工智能实验室的 Marvin Minsky 和 Seymour Papert 提出，人工智能研究应该关注被称为微观世界的人工简单情境[j]。他们指出，在物理学等成功的科学领域，通常使用简化模型（例如无摩擦平面或完全刚体）来最好地理解基本原理。大部分研究都集中在“积木世界”上，这个世界由排列在平面上、形状和大小各异的彩色积木组成。

这一范式促成了杰拉尔德·萨斯曼、阿道夫·古兹曼、大卫·沃尔兹（发明了“约束传播”），尤其是帕特里克·温斯顿等人在机器视觉领域的创新性工作。与此同时，明斯基和帕普特制造了一个可以堆叠积木的机械臂，让积木世界变得栩栩如生。特里·维诺格拉德的SHRDLU可以用普通的英语句子来交流微观世界，规划并执行操作。

#### 感知器和早期神经网络

*主条目：感知器*

20世纪60年代，资金主要用于研究符号人工智能的实验室，但仍有少数人从事神经网络的研究。

Mark 1 感知器
感知器是一种单层神经网络，由弗兰克·罗森布拉特（Frank Rosenblatt）于 1958 年发明（他曾是马文·明斯基在布朗克斯科学高中的同学）。 与大多数人工智能研究人员一样，他对感知器的能力持乐观态度，并预测感知器“最终可能能够学习、做出决策并翻译语言”。 罗森布拉特的研究主要由海军研究办公室资助。

伯纳德·威德罗（Bernard Widrow）和他的学生泰德·霍夫（Ted Hoff）建造了 ADALINE（1960 年）和 MADALINE（1962 年），它们拥有多达 1000 个可调权重。 斯坦福研究所的查尔斯·A·罗森（Charles A. Rosen）和阿尔弗雷德·E·（泰德）·布莱恩（Alfred E. (Ted) Brain) 领导的一个团队建造了两台神经网络机器，分别名为 MINOS I（1960 年）和 MINOS II（1963 年）。

MINOS II 拥有 6600 个可调权重，并由一台名为 MINOS III（1968 年）的 SDS 910 计算机控制，该计算机可以对军用地图上的符号进行分类，并识别 Fortran 编码表上的手写字符。 早期的神经网络研究大多涉及构建和使用定制硬件，而不是在数字计算机上进行模拟。[k]

然而，部分由于缺乏成果，部分由于来自符号人工智能研究的竞争，MINOS 项目在 1966 年耗尽了资金。罗森布拉特在 20 世纪 60 年代未能获得持续的资金支持。 1969 年，随着明斯基和帕普特 1969 年出版的《感知器》一书，研究突然停滞。这本书表明感知器的功能存在严重局限性，Rosenblatt 的预测被严重夸大了。这本书的影响是，十年来几乎没有任何联结主义研究获得资助。 政府资金的竞争以符号人工智能方法战胜神经网络而告终。

明斯基（曾参与 SNARC 项目）成为纯联结主义人工智能的坚定反对者。Widrow（曾参与 ADALINE 项目）转向自适应信号处理。SRI 团队（曾参与 MINOS 项目）转向符号人工智能和机器人技术。

主要问题是无法训练多层网络（反向传播算法的各种版本已经在其他领域得到应用，但这些研究人员对此并不了解）。人工智能界在 80 年代意识到了反向传播，到了 21 世纪，神经网络取得了巨大的成功，实现了罗森布拉特的所有乐观预测。然而，罗森布拉特未能亲眼见证这一切，他于 1971 年在一场船难中丧生。

### 乐观主义

第一代人工智能研究人员对他们的工作做出了以下预测：

1958年，H. A. Simon 和 Allen Newell：“十年内，一台数字计算机将成为世界象棋冠军”和“十年内，一台数字计算机将发现并证明一个重要的新数学定理。”
1965年，H. A. Simon：“二十年内，机器将能够完成人类所能做的任何工作。”
1967年，Marvin Minsky：“在一代人的时间内……创造‘人工智能’的问题将得到实质性解决。”
1970年，Marvin Minsky（在《生活》杂志上）：“三到八年内，我们将拥有一台具有普通人类智能的机器。”[l]

### 资金

1963年6月，麻省理工学院从新成立的高级研究计划局（ARPA，后来称为DARPA）获得了220万美元的资助。这笔资金被用于资助MAC项目，该项目整合了明斯基和麦卡锡五年前创立的“人工智能小组”。DARPA每年持续提供300万美元，直到70年代。 DARPA也向卡内基梅隆大学的纽厄尔和西蒙项目以及约翰·麦卡锡于1963年创立的斯坦福大学人工智能实验室提供了类似的资助。 另一个重要的人工智能实验室由唐纳德·米奇于1965年在爱丁堡大学建立。 这四个机构多年来一直是学术界人工智能研究和资助的主要中心。[m]

这笔资金几乎没有附加条件：时任ARPA主任的J. C. R. 利克莱德认为，他的机构应该“资助人，而不是项目！”，并允许研究人员探索他们感兴趣的任何方向。这在麻省理工学院营造了一种自由放任的氛围，催生了黑客文化，但这种“放手”的做法并没有持续太久。

## 人工智能的第一个寒冬（1974-1980）

20世纪70年代，人工智能饱受批评和资金困境。人工智能研究人员未能充分认识到他们所面临问题的难度。他们极度乐观的态度使公众的期望值过高，而当承诺的成果未能实现时，针对人工智能的资金也大幅减少。 缺乏成果表明，当时人工智能研究人员所使用的技术不足以实现他们的目标。

然而，这些挫折并没有影响该领域的发展和进步。资金削减仅影响了少数几个主要实验室，批评意见也基本被忽视了。公众对该领域的兴趣持续增长，研究人员的数量急剧增加，逻辑编程、常识推理和许多其他领域也涌现出新的思路。历史学家托马斯·海格在2023年指出，人工智能的寒冬并不存在，而人工智能研究员尼尔斯·尼尔森则将这一时期描述为人工智能领域最“激动人心”的时期。

### 问题

在20世纪70年代早期，人工智能程序的能力有限。即使是最强大的程序也只能处理它们需要解决的问题的简单版本[n]；从某种意义上说，所有的程序都只是“玩具”。人工智能研究人员开始遇到一些限制有些难题直到几十年后才被攻克，而其他难题在2020年代仍然阻碍着该领域的发展：

+ 计算机能力有限：当时的内存和处理速度不足以完成任何真正有用的任务。[o] 例如：罗斯·奎利安（Ross Quillian）在自然语言方面的成功工作，就是用只有20个词的词汇量来证明的，因为内存只能容纳20个词。 汉斯·莫拉维克（Hans Moravec）在1976年指出，计算机的性能仍然比人类弱数百万倍，无法展现智能。他提出了一个类比：人工智能需要计算机能力，就像飞机需要马力一样。低于某个阈值时，人工智能是不可能的，但随着马力的增加，最终会变得容易。“只要马力足够，”他写道，“任何东西都能飞起来”。[p]
+ 难解性和组合爆炸：1972年，理查德·卡普（Richard Karp）基于斯蒂芬·库克（Stephen Cook）1971年的定理）表明，许多问题只能在指数时间内解决。寻找这些问题的最优解需要耗费大量的计算机时间，除非问题本身很简单。这种限制适用于所有使用搜索树的符号式人工智能程序，这意味着人工智能使用的许多“玩具”解决方案永远无法扩展到有用的系统。
+ 莫拉维克悖论：早期的人工智能研究在让计算机执行“智能”任务方面非常成功，例如证明定理、解决几何问题和下棋。它们在这些智能任务上的成功使它们相信，智能行为的问题已基本得到解决。 然而，它们在“非智能”任务上却完全没有取得进展，例如识别人脸或穿过房间而不撞到任何东西。 到了 20 世纪 80 年代，研究人员意识到符号推理完全不适合这些感知和感觉运动任务，并且这种方法存在局限性。
+ 常识知识的广度：许多重要的人工智能应用，例如视觉或自然语言，都需要海量的世界信息：程序需要了解它可能看到的是什么或正在谈论的内容。这就要求程序能够像孩子一样，对世界有大致的了解。研究人员很快发现，这是一个包含数十亿个原子事实的庞大信息量。1970年，没有人能够构建足够大的数据库，也没有人知道程序如何学习如此多的信息。
+ 常识推理的表示：当研究人员尝试使用形式逻辑或符号来表示常识推理时，出现了许多相关问题[q]。对非常普通的推理的描述往往会随着研究的深入而变得越来越长，因为需要越来越多的例外、澄清和区分。[r] 然而，当人们思考普通概念时，他们并不依赖于精确的定义，而是似乎会做出数百个不精确的假设，并在必要时运用他们所有的常识知识来纠正这些假设。杰拉尔德·萨斯曼 (Gerald Sussman) 曾指出：“用精确的语言来描述本质上不精确的概念，并不能使它们变得更加精确。”

### 资金减少

另见：人工智能寒冬
资助人工智能研究的机构，例如英国政府、美国国防部高级研究计划局 (DARPA) 和美国国家研究委员会 (NRC)，对缺乏进展感到沮丧，最终切断了几乎所有对无方向人工智能研究的资助。这种模式始于 1966 年，当时自动语言处理咨询委员会 (ALPAC) 的报告批评了机器翻译工作。在花费了 2000 万美元后，NRC 终止了所有支持。 1973 年，莱特希尔 (Lighthill) 关于英国人工智能研究状况的报告批评了人工智能未能实现其“宏伟目标”，并导致该国人工智能研究的解散。 （该报告特别提到组合爆炸问题是人工智能失败的原因之一。）[s] DARPA 对卡内基梅隆大学语音理解研究项目的研究人员深感失望，取消了每年 300 万美元的拨款。[t]

汉斯·莫拉维克将这场危机归咎于同事们不切实际的预测。“许多研究人员陷入了日益夸张的陷阱。”[u] 然而，还有另一个问题：自 1969 年《曼斯菲尔德修正案》通过以来，DARPA 一直面临着越来越大的压力，要求其资助“以任务为导向的直接研究，而不是基础性的无方向研究”。 60年代进行的那些富有创意、自由探索的资金并非来自DARPA，而是用于目标明确的特定项目，例如自主坦克和战斗管理系统。[v]

各大实验室（麻省理工学院、斯坦福大学、卡内基梅隆大学和爱丁堡大学）一直得到政府的慷慨支持，当政府撤回支持时，这些地方是唯一受到严重影响的地方。预算削减，这些机构之外的数千名研究人员以及更多加入该领域的研究人员并未受到影响。

### 哲学与伦理批判

另见：人工智能哲学
一些哲学家强烈反对人工智能研究人员的主张。最早的一位是约翰·卢卡斯，他认为哥德尔不完备定理表明，形式系统（例如计算机程序）永远无法看到某些陈述的真实性，而人类可以。休伯特·德雷福斯（Hubert Dreyfus）嘲笑了20世纪60年代那些未能兑现的承诺，并批判了人工智能的假设，认为人类的推理实际上很少涉及“符号处理”，而大量涉及具体化、本能化和无意识的“知识”。[w] 约翰·塞尔（John Searle）于1980年提出的“中文房间”论证试图表明，程序不能被说成“理解”它所使用的符号（这种特质被称为“意向性”）。塞尔认为，如果这些符号对机器来说毫无意义，那么机器就不能被描述为“思考”。

这些批评并未引起人工智能研究人员的重视。诸如难解性和常识性等问题似乎更为紧迫和严重。“知识”或“意向性”对实际的计算机程序有何影响尚不清楚。麻省理工学院的明斯基谈到德雷福斯和塞尔时说：“他们误解了，应该被忽视。” 同样在麻省理工学院任教的德雷福斯受到了冷遇：他后来表示，人工智能研究人员“不敢让人看到他们和我一起吃午饭”。 ELIZA 的作者约瑟夫·魏泽鲍姆也直言不讳地批评德雷福斯的立场，但他“故意表明（他的人工智能同事对待德雷福斯的方式）并非对待人类的方式”[x]，并且显得不专业且幼稚。

当肯尼斯·科尔比基于 ELIZA 编写了一个“可以进行心理治疗对话的计算机程序”时，魏泽鲍姆开始对人工智能产生了严重的伦理怀疑。[y] 魏泽鲍姆对科尔比将一个没有思维的程序视为一种严肃的治疗工具感到不安。一场争执由此开始，科尔比没有认可魏森鲍姆对该程序的贡献，这更加剧了局势的恶化。1976年，魏森鲍姆发表了《计算机能力与人类理性》，指出人工智能的滥用可能会贬低人类的生命价值。

### 斯坦福大学、卡内基梅隆大学和爱丁堡大学的逻辑学

早在1958年，约翰·麦卡锡就在他的“Advice Taker”提案中将逻辑学引入了人工智能研究。 1963年，J·艾伦·罗宾逊发现了一种在计算机上实现演绎的简单方法，即归结与统一算法。 然而，像麦卡锡和他的学生在20世纪60年代末尝试的那样，直接的实现尤其难以实现：这些程序需要天文数字般的步骤来证明简单的定理。 20 世纪 70 年代，爱丁堡大学的罗伯特·科瓦尔斯基 (Robert Kowalski) 发展了一种更为卓有成效的逻辑方法，并很快促成了与法国研究人员阿兰·科尔默劳尔 (Alain Colmerauer) 和菲利普·鲁塞尔 (Philippe Roussel) [fr] 的合作，他们创建了成功的逻辑编程语言 Prolog。 Prolog 使用逻辑的一个子集（霍恩子句，与“规则”和“产生式规则”密切相关），从而实现易于处理的计算。规则将继续发挥影响力，为爱德华·费根鲍姆 (Edward Feigenbaum) 的专家系统以及艾伦·纽厄尔 (Allen Newell) 和赫伯特·A·西蒙 (Herbert A. Simon) 的后续工作奠定了基础，最终催生了索尔 (Soar) 及其统一的认知理论。

正如德雷福斯 (Dreyfus) 所指出的那样，对逻辑方法的批评者指出，人类在解决问题时很少运用逻辑。彼得·沃森 (Peter Wason)、埃莉诺·罗施 (Eleanor Rosch)、阿莫斯·特沃斯基 (Amos Tversky)、丹尼尔·卡尼曼 (Daniel Kahneman) 等心理学家的实验提供了证据。[z] 麦卡锡回应说，人们的行为无关紧要。他认为，真正需要的是能够解决问题的机器，而不是像人一样思考的机器。[aa]

### 麻省理工学院的“反逻辑”方法

批评麦卡锡方法的，包括他在麻省理工学院全国各地的同事。马文·明斯基、西摩·帕普特和罗杰·尚克试图解决“故事理解”和“物体识别”等问题，这些问题需要机器像人一样思考。为了使用“椅子”或“餐厅”等普通概念，他们不得不做出所有与人类通常所做的相同的不合逻辑的假设。不幸的是，像这样不精确的概念很难用逻辑来表达。麻省理工学院选择专注于编写程序来解决给定的任务，而无需使用高级抽象定义或一般认知理论，并通过迭代测试而不是基于第一原理的论证来衡量性能。尚克认为，他们的“反逻辑”方法粗制滥造，与麦卡锡、科瓦尔斯基、费根鲍姆、纽厄尔和西蒙等人使用的简洁范式截然不同。[ab]

1975年，明斯基在一篇开创性的论文中指出，他的许多同行研究人员都在使用同一种工具：一个框架，它囊括了我们对某事物的所有常识性假设。例如，如果我们使用鸟的概念，一系列事实会立即浮现在脑海中：我们可能会假设它会飞、吃虫子等等（这些假设并非对所有鸟类都成立）。明斯基将这些假设与广义范畴联系起来，它们可以被子范畴和个体的框架继承，或者根据需要被覆盖。他将这些结构称为框架。Schank 使用一种他称之为“脚本”的框架版本，成功地回答了关于英语短篇小说的问题。 框架最终以面向对象编程的名义广泛应用于软件工程。

逻辑学家们迎接了挑战。帕特·海耶斯声称“大多数‘框架’只是一阶逻辑部分的新语法”。但他指出，“有一两个看似微不足道的细节，尤其是默认值，却会带来很多麻烦”。

雷·赖特承认，“传统逻辑，例如一阶逻辑，缺乏足够的表达能力，无法充分表达默认推理所需的知识”。 他建议用一个封闭世界假设来增强一阶逻辑，即如果无法证明结论的反面，则结论默认成立。他展示了这种假设如何与框架推理中的常识性假设相对应。他还表明，它在Prolog语言中存在“程序等价物”，即否定失败。赖特所表述的封闭世界假设“并非一阶概念。（它是一个元概念。）” 然而，基思·克拉克表明，否定有限失败可以理解为在一阶逻辑中隐式地使用定义进行推理，其中包括一个唯一名称假设，即不同的术语表示不同的个体。

在20世纪70年代末和整个80年代，人们开发了各种各样的逻辑和一阶逻辑的扩展，用于解决逻辑编程中“否定即失败”的问题，以及更普遍的默认推理。这些逻辑统称为非单调逻辑。

## 繁荣期（1980-1987）

20世纪80年代，一种名为“专家系统”的人工智能程序被世界各地的公司采用，知识成为主流人工智能研究的焦点。各国政府提供了大量资金，例如日本的第五代计算机项目和美国的战略计算计划。“总体而言，人工智能产业从1980年的几百万美元蓬勃发展到1988年的数十亿美元。”

### 专家系统得到广泛应用

专家系统是一种程序，它使用源自专家知识的逻辑规则来回答或解决特定知识领域的问题。最早的例子是由爱德华·费根鲍姆和他的学生开发的。Dendral 于 1965 年开始研发，它通过光谱仪读数识别化合物。 MYCIN 于 1972 年开发，用于诊断传染性血液疾病。 他们证明了该方法的可行性。

专家系统将自身限制在特定知识的小领域（从而避免了常识性知识问题），其简单的设计使得程序的构建和修改都相对容易。总而言之，这些程序被证明是有用的：这是人工智能迄今为止未能实现的。

1980 年，卡内基梅隆大学为数字设备公司开发了一个名为 R1 的专家系统。这是一个巨大的成功：到 1986 年，它每年为公司节省了 4000 万美元。世界各地的公司开始开发和部署专家系统，到 1985 年，它们在人工智能方面的投入已超过 10 亿美元，其中大部分用于公司内部的人工智能部门。 一个支持这些系统的行业应运而生，包括 Symbolics 和 Lisp Machines 等硬件公司，以及 IntelliCorp 和 Aion 等软件公司。

### 政府资金增加

1981 年，日本通商产业省为第五代计算机项目拨款 8.5 亿美元。该项目的目标是编写程序并制造能够像人类一样进行对话、翻译语言、解读图像和推理的机器。 令“邋遢”们懊恼的是，他们最初选择 Prolog 作为该项目的主要计算机语言。

其他国家也纷纷响应，推出了自己的新项目。英国启动了耗资 3.5 亿英镑的 Alvey 项目。一个由美国公司组成的财团成立了微电子与计算机技术公司（简称“MCC”），为人工智能和信息技术领域的大型项目提供资金。 美国国防部高级研究计划局（DARPA）也做出了回应，成立了战略计算计划，并在1984年至1988年间将其对人工智能的投资增加了两倍。

### 知识革命

专家系统的力量源于其所蕴含的专家知识。它们是人工智能研究新方向的一部分，该方向在70年代得到了广泛的应用。“人工智能研究人员开始怀疑——尽管他们很不情愿，因为这违反了科学的简约原则——智能很可能基于以不同方式运用大量不同知识的能力，”帕梅拉·麦考达克写道。“20世纪70年代的重要教训是，智能行为在很大程度上取决于处理特定任务所在领域的知识，有时是相当详细的知识。”基于知识的系统和知识工程成为20世纪80年代人工智能研究的主要焦点。人们希望庞大的数据库能够解决常识性知识问题，并提供常识性推理所需的支持。

在20世纪80年代，一些研究人员试图直接攻克常识性知识问题，他们创建了一个包含普通人所知所有日常事实的庞大数据库。道格拉斯·莱纳特（Douglas Lenat）创建了一个名为 Cyc 的数据库，他认为没有捷径——机器理解人类概念含义的唯一方法是手动地逐个概念地教它们。

## 20 世纪 80 年代的新方向

尽管符号知识表示和逻辑推理在 80 年代产生了实用的应用，并获得了大量资金，但它仍然无法解决感知、机器人、学习和常识方面的问题。少数科学家和工程师开始怀疑符号方法是否足以完成这些任务，并开发了其他方法，例如“联结主义”、机器人技术、“软”计算和强化学习。尼尔斯·尼尔森（Nils Nilsson）称这些方法为“亚符号的”。

### 神经网络的复兴：“联结主义”

1982年，物理学家约翰·霍普菲尔德证明了一种神经网络（现称为“霍普菲尔德网络”）能够学习和处理信息，并且可证明其在任何固定条件下经过足够时间后会收敛。这是一个突破，因为此前人们认为非线性网络通常会以混沌的方式演化。 大约在同一时期，杰弗里·辛顿和大卫·鲁梅尔哈特推广了一种名为“反向传播”的神经网络训练方法。[ac] 这两项进展有助于复兴对人工神经网络的探索。

自1986年鲁梅尔哈特和心理学家詹姆斯·麦克莱兰编辑的两卷本论文集《并行分布式处理》出版以来，神经网络以及其他一些类似模型受到了广泛关注。这个新领域被命名为“联结主义”，符号人工智能的倡导者和“联结主义者”之间展开了激烈的争论。 辛顿将符号称为“人工智能的光之以太”，即一种不切实际且具有误导性的智能模型。 这直接攻击了激发认知革命的原则。

神经网络开始在一些专业领域（例如蛋白质结构预测）取得突破性进展。继特里·塞诺夫斯基（Terry Sejnowski）的开创性工作之后， 级联多层感知器（例如 PhD 和 PsiPred）在预测二级结构方面达到了接近理论最大值的准确率。

1990 年，贝尔实验室的 Yann LeCun 使用卷积神经网络识别手写数字。该系统在 90 年代得到广泛应用，用于读取邮政编码和个人支票。这是神经网络的第一个真正有用的应用。

### 机器人技术与具身理性

主要文章：新型人工智能、基于行为的人工智能、情境化人工智能和具身认知科学
罗德尼·布鲁克斯 (Rodney Brooks)、汉斯·莫拉维克 (Hans Moravec) 等人认为，为了展现真正的智能，机器需要拥有躯体——它需要感知、移动、生存和应对世界。 感觉运动技能对于常识推理等高级技能至关重要。抽象的符号推理无法有效地实现这些技能，因此人工智能应该完全不使用符号表征来解决感知、移动、操控和生存的问题。这些机器人研究人员主张“自下而上”构建智能。

这一理念的先驱是大卫·马尔 (David Marr)，他凭借在理论神经科学领域的成功经验，于 20 世纪 70 年代末来到麻省理工学院，领导视觉研究小组。他拒绝了所有符号方法（包括麦卡锡的逻辑和明斯基的框架），认为人工智能需要自下而上地理解视觉的物理机制，然后才能进行任何符号处理。 （马尔的研究因1980年白血病而被迫中断。）

机器人研究员布鲁克斯在其1990年的论文《大象不下棋》中直接批判了物理符号系统假说，他认为符号并非总是必要的，因为“世界本身就是它最好的模型。它总是准确地保持最新状态。它总是包含所有需要了解的细节。关键在于恰当地、足够频繁地感知它。”

在20世纪80年代和90年代，许多认知科学家也否定了心智的符号处理模型，并认为身体对于推理至关重要，这一理论被称为“具身心智论”。

### 软计算与概率推理

软计算使用处理不完整和不精确信息的方法。它们并不试图给出精确的、合乎逻辑的答案，而是给出仅“可能”正确的结果。这使得它们能够解决精确符号方法无法处理的问题。媒体报道经常声称这些工具可以“像人类一样思考”。

Judea Pearl 于 1988 年出版的颇具影响力的著作《智能系统中的概率推理：似真推理网络》将概率论和决策理论引入了人工智能。 Lofti Zadeh 在 20 世纪 60 年代开发的模糊逻辑开始在人工智能和机器人技术领域得到更广泛的应用。进化计算和人工神经网络也能处理不精确的信息，因此被归类为“软”计算。在20世纪90年代和21世纪初，许多其他软计算工具被开发并投入使用，包括贝叶斯网络、隐马尔可夫模型、信息论和随机建模。这些工具又依赖于经典优化等先进的数学技术。在20世纪90年代和21世纪初的一段时间里，这些软计算工具被人工智能的一个分支领域“计算智能”研究。

### 强化学习

强化学习是指智能体每次出色地完成期望动作时都会获得奖励，而当其表现不佳时，可能会给予负面奖励（或“惩罚”）。20世纪上半叶，一些心理学家，例如桑代克、巴甫洛夫和斯金纳，利用动物模型对其进行了描述。 20 世纪 50 年代，艾伦·图灵和亚瑟·塞缪尔预见了强化学习在人工智能中的作用。

从 1972 年开始，理查德·萨顿和安德鲁·巴托领导了一项成功且影响深远的研究项目。他们的合作彻底改变了四十年来强化学习和决策的研究。 1988 年，萨顿用决策理论（即马尔可夫决策过程）来描述机器学习。这为该学科奠定了坚实的理论基础，并使其能够获取运筹学领域大量的理论成果。

同样在 1988 年，萨顿和巴托开发了“时间差分”（TD）学习算法，该算法中，只有当智能体对未来的预测有所改善时，智能体才会获得奖励。该算法的表现显著优于之前的算法。 1992年，杰拉尔德·特萨罗（Gerald Tesauro）在程序TD-Gammon中使用了时间差分学习（TD-Gammon），该程序在西洋双陆棋（PCG）游戏中的表现堪比人类顶尖高手。该程序通过零先验知识的自我对抗来学习游戏。 一个有趣的跨学科融合案例是，神经学家在1997年发现，大脑中的多巴胺奖励系统也使用了TD学习算法的某个版本。 TD学习在21世纪产生了巨大的影响，AlphaGo和AlphaZero都采用了该算法。

## 第二次人工智能寒冬（20世纪90年代）

20世纪80年代，商界对人工智能的迷恋经历了典型的经济泡沫模式。随着数十家公司的倒闭，商界普遍认为这项技术不可行。 人工智能声誉的受损将持续到21世纪。人工智能未能实现人类水平智能的梦想，这一梦想曾在20世纪60年代俘获了全世界的想象力，但业内人士对此原因众说纷纭。所有这些因素共同作用，导致人工智能分裂成多个相互竞争的子领域，专注于特定的问题或方法，有时甚至冠以新的名称，掩盖了“人工智能”这一污点的血统。

在接下来的20年里，人工智能持续不断地为特定的孤立问题提供可行的解决方案。到20世纪90年代末，它已在整个科技行业得到应用，尽管有些默默无闻。人工智能的成功归功于计算机能力的提升、与其他领域（例如数学优化和统计学）的合作，以及更高的科学问责标准。

### 人工智能寒冬

“人工智能寒冬”一词是由那些在1974年资金削减后幸存下来的研究人员创造的，当时他们担心对专家系统的热情会失控，失望情绪必然会随之而来。[ae] 他们的担忧并非空穴来风：在20世纪80年代末和90年代初，人工智能遭受了一系列财务挫折。

第一个迹象是1987年专用人工智能硬件市场的突然崩溃。苹果和IBM的台式电脑一直在稳步提升速度和性能，到1987年，它们的性能甚至超过了Symbolics和其他公司生产的更昂贵的Lisp机器。购买它们的理由已经不复存在。一个价值5亿美元的整个行业被摧毁一夜之间就完成了。

最终，最早成功的专家系统，例如XCON，被证明维护成本过高。它们难以更新，无法学习，而且“脆弱”（即，当输入异常信息时，它们可能会犯下可怕的错误）。专家系统被证明是有用的，但仅限于少数特殊情况。

20世纪80年代末，战略计算计划“大幅而残酷地”削减了对人工智能的资助。美国国防部高级研究计划局（DARPA）的新领导层认为人工智能并非“下一波浪潮”，并将资金投向了那些更有可能立即产生成果的项目。

到1991年，日本第五代计算机项目在1981年提出的一系列令人印象深刻的目标尚未实现。其中一些目标，例如“进行随意的对话”，在未来30年内都无法实现。与其他人工智能项目一样，人们对其的期望远高于实际可能实现的水平。[af]

截至 1993 年底，超过 300 家人工智能公司倒闭、破产或被收购，人工智能的第一波商业浪潮宣告终结。 1994 年，HP Newquist 在《大脑制造者》一书中指出：“人工智能的近期未来——就其商业形式而言——似乎部分取决于神经网络的持续成功。”

### 人工智能幕后

20 世纪 90 年代，最初由人工智能研究人员开发的算法开始作为更大系统的一部分出现。人工智能解决了许多非常棘手的问题[ag]，其解决方案被证明在整个科技行业都大有裨益， 例如数据挖掘、工业机器人、物流、语音识别、 银行软件、 医疗诊断 以及谷歌搜索引擎。

人工智能领域在20世纪90年代和21世纪初取得的这些成就几乎没有得到任何赞誉。许多人工智能最伟大的创新已被贬低为计算机科学工具箱中的一件普通物品。 尼克·博斯特罗姆解释说：“许多前沿的人工智能已经渗透到一般应用中，通常不被称为人工智能，因为一旦某些东西变得足够有用和普遍，它就不再被称为人工智能了。”

20世纪90年代，许多人工智能研究人员故意用其他名称来称呼他们的工作，例如信息学、基于知识的系统、“认知系统”或计算智能。部分原因可能是他们认为他们的领域与人工智能有着根本的不同，但这些新名称也有助于获得资金。至少在商业领域，人工智能寒冬未能兑现的承诺一直困扰着人工智能研究，直到21世纪初。正如《纽约时报》在2005年报道的那样：“计算机科学家和软件工程师们避免使用‘人工智能’这个词，因为他们担心被视为不切实际的梦想家。”

### 数学严谨性、更紧密的合作和更狭窄的关注点

人工智能研究人员开始比以往任何时候都更多地开发和使用复杂的数学工具。 人工智能的大多数新方向都严重依赖于数学模型，包括人工神经网络、概率推理、软计算和强化学习。在90年代和21世纪初，许多其他高度数学化的工具被应用于人工智能。这些工具被应用于机器学习、感知和移动出行领域。

人们普遍意识到，人工智能需要解决的许多问题，统计学、数学、电子工程、经济学或运筹学等领域的研究人员已经在研究。共享的数学语言既促进了与更成熟、更成功的领域的更高层次的合作，也促成了可衡量和可证明的成果；人工智能已成为一门更加严谨的“科学”学科。90年代成功的另一个关键原因是，人工智能研究人员专注于具有可验证解决方案的特定问题（这种方法后来被嘲笑为狭义人工智能）。这为当下提供了有用的工具，而不是对未来的猜测。

### 智能代理

一种名为“智能代理”的新范式在20世纪90年代被广泛接受。 尽管早期的研究人员已经提出了模块化的“分而治之”的人工智能方法，[ai]但直到朱迪亚·珀尔、艾伦·纽厄尔、莱斯利·P·凯尔布林等人将决策理论和经济学的概念引入人工智能研究，智能代理才形成了现代形态。 当经济学家对理性代理的定义与计算机科学对对象或模块的定义相结合时，智能代理范式就完成了。

智能代理是一种能够感知环境并采取行动以最大化其成功概率的系统。根据此定义，解决特定问题的简单程序属于“智能代理”，人类以及人类组织（例如公司）也属于“智能代理”。智能代理范式将人工智能研究定义为“对智能代理的研究”。[aj] 这是对一些早期定义的概括。人工智能的定义：它超越了对人类智能的研究；它研究各种智能。这种范式允许研究人员研究孤立的问题，并在方法上持有不同意见，但仍然希望他们的工作能够整合成一个能够实现通用智能的代理架构。

### 里程碑与摩尔定律

1997年5月11日，深蓝成为第一个击败卫冕世界象棋冠军加里·卡斯帕罗夫的计算机象棋系统。 2005年，斯坦福大学的机器人赢得了DARPA大挑战赛，它在一条未经规划的沙漠小路上自动驾驶了131英里。两年后，卡内基梅隆大学的一个团队赢得了DARPA城市挑战赛，它在城市环境中自主导航了55英里，同时应对交通危险并遵守交通法规。

这些成功并非源于某种革命性的新范式，而主要归功于工程技术的精湛应用，以及 90 年代计算机速度和容量的大幅提升。[ak] 事实上，深蓝计算机的速度比克里斯托弗·斯特雷奇 (Christopher Strachey) 在 1951 年教他下棋的费兰蒂马克 1 号 (Ferranti Mark 1) 快 1000 万倍。[al] 这一显著提升符合摩尔定律，该定律预测计算机的速度和内存容量每两年翻一番。“原始计算机能力”这一根本问题正在逐渐被克服。

### 人工智能对艺术和文学的影响

电子文学实验，例如《无常特工》（1998-2002），以及数字艺术，例如《鲁比特工》，在其艺术和文学作品中运用了人工智能，“揭露了那些假装客观的技术形式所伴随的偏见”。

## 大数据、深度学习、通用人工智能（2005-2017）

在21世纪的最初几十年，海量数据（被称为“大数据”）的获取、更便宜、更快速的计算机以及先进的机器学习技术被成功应用于解决经济领域的诸多问题。深度学习在2012年左右的成功是一个转折点，它提升了机器学习在许多任务上的性能，包括图像和视频处理、文本分析和语音识别。 随着人工智能能力的提升，对人工智能的投资也随之增加，到2016年，人工智能相关产品、硬件和软件的市场规模已超过80亿美元，《纽约时报》报道称，人们对人工智能的兴趣已达到“狂热”的程度。

2002年，本·格策尔（Ben Goertzel）等人开始担心人工智能在很大程度上已经放弃了其最初打造多功能、全智能机器的目标，并主张对通用人工智能（AGI）进行更直接的研究。到2010年代中期，一些公司和机构成立，致力于开发通用人工智能，例如OpenAI和谷歌的DeepMind。同一时期，对超级智能的新见解引发了人们对人工智能构成生存威胁的担忧。2016年后，人工智能技术的风险和意外后果成为严肃学术研究的一个领域。

### 大数据与大型机器

另见：机器学习研究数据集列表
机器学习在21世纪的成功依赖于海量训练数据的可用性和更快的计算机。 Russell 和 Norvig 写道：“将数据集规模增加两三个数量级所带来的性能提升，远胜于通过调整算法所能带来的任何改进。” Geoffrey Hinton 回忆说，在 90 年代，问题在于“我们的标记数据集小了数千倍，[而且]我们的计算机速度慢了数百万倍。” 到 2010 年，这种情况已不复存在。

21 世纪最有用的数据来自专为机器学习和人工智能创建的精选标记数据集。2007 年，马萨诸塞大学阿默斯特分校的一个团队发布了“Labeled Faces in the Wild”，这是一组带注释的人脸图像，在接下来的几十年里被广泛用于训练和测试人脸识别系统。 李飞飞开发了 ImageNet，这是一个包含 300 万张图像的数据库，这些图像由志愿者使用 Amazon Mechanical Turk 标注。该数据库于 2009 年发布，是一套实用的训练数据，也是测试下一代图像处理系统的基准。 谷歌于 2013 年将 word2vec 作为开源资源发布。它利用从互联网上抓取的大量文本数据，并结合词向量，创建一个数字向量来表示每个单词。用户对其捕捉词义的能力感到惊讶，例如，普通的向量加法就能得出“中国 + 河流 = 长江”或“伦敦 - 英国 + 法国 = 巴黎”这样的等价词。 该数据库对于 2010 年代后期大型语言模型的开发至关重要。

互联网的爆炸式增长使机器学习程序能够访问数十亿页可供抓取的文本和图像。此外，对于特定问题，大型私人数据库也包含相关数据。麦肯锡全球信息该研究所报告称，“到2009年，美国经济中几乎所有行业平均存储的数据量至少达到200TB”。 这类信息在21世纪初被称为大数据。

在2011年2月的一场《危险边缘！》（Jeopardy!）表演赛中，IBM的问答系统“沃森”（Watson）以显著优势击败了《危险边缘！》的两位冠军——布拉德·鲁特（Brad Rutter）和肯·詹宁斯（Ken Jennings）。 如果没有互联网上的信息，沃森的专业知识是不可能实现的。

### 深度学习

*主条目：深度学习*

2012年，由亚历克斯·克里热夫斯基（Alex Krizhevsky）开发的深度学习模型AlexNet赢得了ImageNet大规模视觉识别挑战赛的冠军，其错误率远低于第二名。 Krizhevsky 与多伦多大学的 Geoffrey Hinton 合作。[an] 这是机器学习的一个转折点：在接下来的几年里，数十种其他图像识别方法被深度学习所取代。

深度学习使用多层感知器。尽管这种架构自 20 世纪 60 年代就已为人所知，但要使其发挥作用需要强大的硬件和大量的训练数据。 在这些技术出现之前，提升图像处理系统的性能需要手动设计一些难以实现的临时特征。 而深度学习则更简单，也更通用。[ao]

在接下来的几年里，深度学习被应用于数十个问题（例如语音识别、机器翻译、医疗诊断和游戏）。在每一个案例中，它都表现出了巨大的性能提升。 因此，对人工智能的投资和兴趣蓬勃发展。

### 对齐问题

*主条目：AI 对齐*

21 世纪初，重新讨论人工智能的未来成为一种时尚，一些畅销书探讨了超级智能机器的可能性及其对人类社会的意义。其中一些人持乐观态度（例如雷·库兹韦尔的《奇点临近》），但也有人警告称，足够强大的人工智能将对人类构成生存威胁，例如尼克·博斯特罗姆和埃利泽·尤德科夫斯基。该话题被媒体广泛报道，许多顶尖知识分子和政治家也对此发表了评论。

21 世纪的人工智能程序由其目标定义——即它们旨在优化的具体指标。尼克·博斯特罗姆 2014 年出版的颇具影响力的著作《超级智能》 指出，如果不谨慎定义这些目标，机器在实现目标的过程中可能会对人类造成伤害。斯图尔特·J·罗素（Stuart J. Russell）举了一个例子：一个智能机器人为了防止主人被拔掉电源而杀死了主人，其推理是“如果你死了，就无法去取咖啡”。（这个问题的专业术语是“工具趋同”。）解决方案是使机器的目标函数与其主人以及整个人类的目标保持一致。因此，减轻人工智能风险和意外后果的问题被称为“价值取向问题”或“人工智能取向”。

与此同时，机器学习系统开始产生令人不安的意外后果。 Cathy O'Neil 解释了统计算法是如何成为 2008 年经济危机的原因之一的。 ProPublica 的 Julia Angwin 认为，刑事司法系统使用的 COMPAS 系统在某些方面表现出种族偏见。[ap] 其他研究表明，许多机器学习系统也表现出某种形式的种族偏见。 还有许多其他例子表明机器学习系统导致了危险的后果。[aq]

2016 年，唐纳德·特朗普当选美国总统以及围绕 COMPAS 系统的争议凸显了当前技术基础设施的若干问题，包括虚假信息、旨在最大化参与度的社交媒体算法、个人数据的滥用以及预测模型的可信度。 公平性和意外后果问题在人工智能会议上变得更加热门，出版物数量大幅增加，资金也更加充裕，许多研究人员将他们的职业生涯重新聚焦于这些问题。价值观一致性问题成为了学术界一个严肃的研究领域。[ar]

### 通用人工智能研究

21 世纪初，一些研究人员开始担心主流人工智能过于关注“特定应用中的可衡量性能”（即所谓的“狭义人工智能”），而放弃了人工智能最初的目标，即创造多功能、完全智能的机器。尼尔斯·尼尔森 (Nils Nilsson) 于 1995 年提出了早期的批评，人工智能领域的元老约翰·麦卡锡 (John McCarthy)、马文·明斯基 (Marvin Minsky) 和帕特里克·温斯顿 (Patrick Winston) 也在 2007-2009 年发表了类似的观点。明斯基于 2004 年组织了一场关于“人类水平人工智能”的研讨会。 本·格策尔 (Ben Goertzel) 将这个新的子领域命名为“通用人工智能”，并从 2008 年开始创办期刊并举办会议。 受人工神经网络持续成功的推动，这个新领域迅速发展。并希望它是通用人工智能的关键。

2010年代，多家相互竞争的公司、实验室和基金会应运而生，致力于开发通用人工智能。DeepMind 由三位英国科学家 Demis Hassabis、Shane Legg 和 Mustafa Suleyman 于 2010 年创立，资金来自彼得·泰尔 (Peter Thiel) 和后来的埃隆·马斯克 (Elon Musk)。创始人和投资者对人工智能的安全性和生存风险深感担忧。DeepMind 的创始人与 Yudkowsky 有私交，马斯克也是积极发出警告的人之一。 哈萨比斯既担心通用人工智能的危险，又对其威力持乐观态度；他希望他们能够“先解决人工智能，然后再解决其他所有问题”。 《纽约时报》在2023年写道：“这场竞争的核心是一个令人费解的悖论。那些声称自己最担心人工智能的人，恰恰是最决心创造人工智能并享受其财富的人。他们坚信只有自己才能阻止人工智能危及地球，以此来证明自己的雄心壮志是合理的。”

2012年，杰弗里·辛顿（自上世纪80年代以来一直领导神经网络研究）受到百度的接洽，百度想以巨额资金聘请他和他的所有学生。辛顿决定举行一场拍卖，在太浩湖人工智能会议上，他们以4400万美元的价格将自己卖给了谷歌。哈萨比斯注意到了这一点，并于2014年将DeepMind出售给了谷歌，条件是该公司不接受军事合同，并接受道德委员会的监督。

OpenAI 联合创始人兼首席执行官 Sam Altman
与马斯克和哈萨比斯不同，谷歌的拉里·佩奇对人工智能的未来持乐观态度。在 2015 年马斯克的生日派对上，马斯克和佩奇就通用人工智能 (AGI) 的风险展开了争论。他们几十年来一直是朋友，但不久之后就断绝了联系。马斯克参加了 DeepMind 道德委员会的唯一一次会议，在会上，他清楚地表明谷歌对减轻 AGI 的危害毫无兴趣。由于对自己缺乏影响力感到沮丧，他于 2015 年创立了 OpenAI，并聘请 Sam Altman 负责运营，并聘请了顶尖科学家。OpenAI 最初是一家非营利组织，“不受谷歌和其他公司所依赖的经济激励”。 马斯克再次感到沮丧，并于 2018 年离开了公司。OpenAI 向微软寻求持续的资金支持，而 Altman 和 OpenAI 则成立了一家营利性公司，融资超过 10 亿美元。

2021年，达里奥·阿莫迪（Dario Amodei）和其他14位科学家因担心OpenAI将利润置于安全之上而离开。他们成立了Anthropic，并很快获得了来自微软和谷歌的60亿美元融资。

## 大型语言模型，人工智能热潮（2017年至今）

*主条目：人工智能热潮*

2024年，中国和美国的人工智能专利数量占全球人工智能专利总数的四分之三以上。 尽管中国的人工智能专利数量更多，但美国每位人工智能专利申请公司的专利数量比中国高出35%。

2022年，谷歌搜索“AI”一词的次数加速增长。
人工智能热潮始于2017年Transformer架构等关键架构和算法的初步开发，这推动了大型语言模型的扩展和发展，这些模型展现出类似人类的知识、注意力和创造力等特征。 2020年，随着ChatGPT等可扩展大型语言模型（LLM）的公开发布，人工智能新时代拉开帷幕。

### Transformer架构与大型语言模型

*主条目：大型语言模型*

2017年，谷歌研究人员在题为《Attention Is All You Need》的论文中提出了Transformer架构。该架构利用了自注意力机制，并在大型语言模型中得到了广泛应用。 其他公司基于Transformer架构进一步开发了大型语言模型：OpenAI于2020年发布了GPT-3，DeepMind于2022年发布了Gato。这些模型是基础模型：它们基于海量未标记数据进行训练，可以适应各种下游任务。这些模型可以讨论大量主题并展示通用知识。因此，一个问题自然而然地出现了：这些模型是通用人工智能（AGI）的典型代表吗？

比尔·盖茨对这项新技术以及围绕AGI的炒作持怀疑态度。然而，Altman 向他展示了 ChatGPT-4 的现场演示，并成功通过了一项高级生物学测试。盖茨对此深信不疑。 2023 年，微软研究院用多种任务测试了该模型，并得出结论：“它可以合理地被视为通用人工智能 (AGI) 系统的早期（但尚不完整）版本”。

2024 年，OpenAI 开发的一种高级推理模型 OpenAI o3 发布。在 François Chollet 于 2019 年开发的通用人工智能抽象与推理语料库 (ARC-AGI) 基准测试中，该模型在半公开测试中取得了 87.5% 的非官方得分，超过了人类 84% 的平均得分。该基准测试被认为是必要而非充分的测试。或称通用人工智能 (AGI)。谈到基准，Chollet 曾表示：“当创造对普通人而言轻而易举、但对人工智能而言却困难重重的任务变得根本不可能时，你就知道 AGI 已经到来了。”

### 人工智能投资

2020 年后，人工智能投资呈指数级增长，对生成型人工智能公司的风险投资大幅增加。人工智能总投资从 2014 年的 180 亿美元增长到 2021 年的 1190 亿美元，到 2023 年，生成型人工智能将占总投资的 30% 左右。 根据 2017 年至 2021 年的指标，美国在风险投资资金、初创企业数量和人工智能专利授予数量方面均超过世界其他地区。 商业人工智能领域由美国大型科技公司主导，它们在该领域的投资超过了美国本土风险投资家的投资。到 2024 年初，OpenAI 的估值达到 860 亿美元，而到 2024 年中期，NVIDIA 的市值超过 3.3 万亿美元，随着对支持 AI 的 GPU 的需求激增，NVIDIA 成为全球市值最大的公司。

### 人工智能走向大众应用

15.ai 由一位匿名麻省理工学院的研究人员于 2020 年 3 月推出，是人工智能繁荣初期获得公众广泛关注的生成式人工智能最早的例子之一。这款免费的网络应用程序展示了使用神经网络以最少的训练数据克隆人物声音的能力，只需 15 秒的音频即可重现声音——这一能力后来在 2024 年得到了 OpenAI 的证实。这项服务于2021年初在社交媒体平台上爆红，允许用户为热门影视作品中的角色生成语音，并因其在推广用于创意内容和表情包的AI语音合成方面所发挥的先锋作用而尤为引人注目。

当代人工智能系统如今在一般任务上已具备与人类竞争的实力，我们必须扪心自问：我们是否应该让机器用宣传和谎言充斥我们的信息渠道？我们是否应该将所有工作，包括那些令人满足的工作，都自动化？我们是否应该开发最终可能超越我们、淘汰我们并取代我们的非人类思维？我们是否应该冒着失去对文明控制的风险？这些决定绝不能委托给未经选举的技术领导人。只有当我们确信强大的人工智能系统将产生积极影响且其风险可控时，我们才能开发它们。这种信心必须有充分的理由，并随着系统潜在影响的增强而增强。 OpenAI 最近关于通用人工智能 (AI) 的声明指出：“在某个时候，在开始训练未来系统之前进行独立审查可能很重要，并且最先进的努力应该同意限制用于创建新模型的计算增长率。” 我们同意这一点。现在就是关键时刻。因此，我们呼吁所有人工智能实验室立即暂停训练比 GPT-4 更强大的人工智能系统至少 6 个月。暂停应公开且可验证，并涵盖所有关键参与者。如果无法迅速实施暂停，政府应介入并实施暂停令。暂停大型人工智能实验：一封公开信

ChatGPT 于 2022 年 11 月 30 日上线，标志着人工智能在公众应用方面的关键时刻。发布后的几天内，它迅速走红，在两个月内就吸引了超过 1 亿用户，成为历史上增长最快的消费软件应用程序。聊天机器人能够进行类似人类的对话、编写代码并生成创意内容，这激发了公众的想象力，并迅速在教育、商业和研究等各个领域得到应用。 ChatGPT 的成功引发了各大科技公司前所未有的反应——谷歌宣布“红色警报”，并迅速推出了 Gemini（前身为 Google Bard），而微软则将该技术融入了必应聊天 (Bing Chat)。

这些人工智能技术的迅速普及引发了关于其影响的激烈争论。著名的人工智能研究人员和行业领袖对这种加速的发展既表示乐观，也表示担忧。 2023年3月，超过2万名签名者，包括计算机科学家约书亚·本吉奥、埃隆·马斯克和苹果联合创始人史蒂夫·沃兹尼亚克，签署了一封公开信，呼吁暂停高级人工智能开发，理由是其“将对社会和人类构成巨大风险”。 然而，其他著名研究人员，如于尔根·施米德胡伯，则持更为乐观的态度，强调大多数人工智能研究旨在“让人类生活更长寿、更健康、更轻松”。

然而，到2024年中期，金融业开始更加严格地审查人工智能公司，尤其质疑它们能否产生与其巨额估值相称的投资回报。一些知名投资者对市场预期与基本商业现实脱节表示担忧。杰瑞姆GMO LLC 联合创始人格兰瑟姆警告投资者“要非常小心”，并将其与以往技术驱动的市场泡沫进行了类比。 同样，DoubleLine Capital 首席执行官杰弗里·冈拉克明确地将人工智能热潮与 20 世纪 90 年代末的互联网泡沫进行了比较，指出投资者的热情可能超过了现实的短期能力和收入潜力。 专注于人工智能的公司的巨大市值加剧了这些担忧，其中许多公司尚未展示出可持续的盈利模式。

2024 年 3 月，Anthropic 发布了 Claude 3 系列大型语言模型，包括 Claude 3 Haiku、Sonnet 和 Opus。 这些模型在各种基准测试中都表现出了显著的性能提升，其中 Claude 3 Opus 的表现明显优于 OpenAI 和谷歌的领先模型。 2024年6月，Anthropic发布了Claude 3.5 Sonnet，其性能比Claude 3 Opus更高，尤其是在编码、多步骤工作流程和图像分析等领域。

### 2024年诺贝尔奖

2024年，瑞典皇家科学院颁发诺贝尔奖，以表彰人工智能领域的开创性贡献。获奖者包括：

物理学领域：约翰·霍普菲尔德因其在受物理学启发的霍普菲尔德网络方面的工作而获奖，杰弗里·辛顿因其在玻尔兹曼机和深度学习方面的基础性贡献而获奖。
化学领域：大卫·贝克、德米斯·哈萨比斯和约翰·江珀因其在蛋白质折叠预测方面取得的进展而获奖。参见AlphaFold。

### 人工智能的进一步研究和发展

2025年1月，OpenAI宣布了一项名为ChatGPT-Gov的全新人工智能项目，该项目将专为美国政府机构安全使用而设计。 Open AI 表示，各机构可以在 Microsoft Azure 云或 Azure Government 云上使用 ChatGPT Gov，“在 Microsoft Azure 的 OpenAI 服务之上”。OpenAI 的公告指出：“自托管 ChatGPT Gov 使各机构能够更轻松地管理自身的安全、隐私和合规性要求，例如严格的网络安全框架（IL5、CJIS、ITAR、FedRAMP High）。此外，我们相信，该基础设施将加快 OpenAI 工具处理非公开敏感数据的内部授权。”

### 国家政策

各国已投入政策和资金部署自主机器人，以解决劳动力短缺问题并提高效率，同时实施符合伦理和安全发展的监管框架。

#### 中国

2025 年，中国投资约 7300 亿元人民币（约 1000 亿美元），用于推动智能制造和医疗保健领域的人工智能和机器人技术发展。 “十四五”规划（2021-2025）优先发展服务机器人，人工智能系统使机器人能够执行复杂的任务，例如协助手术或实现工厂装配线自动化。 一些资金还支持国防应用，例如自主无人机。 从2025年9月开始，中国强制要求对人工智能生成的内容进行标注，以确保这些技术的透明度和公众信任。

#### 美国

2025年1月，OpenAI、软银、甲骨文和MGX的合资企业Stargate LLC成立，并宣布计划到2029年在美国投资5000亿美元用于人工智能基础设施建设。美国总统唐纳德·特朗普于2025年1月21日正式宣布成立该合资企业，软银首席执行官孙正义被任命为董事长。

美国政府拨款约20亿美元，用于将人工智能和机器人技术融入制造业和物流业。[需要非主要来源]各州政府还额外拨款用于服务机器人，例如部署在仓库中执行库存管理口头指令的机器人，或部署在老年护理机构中响应居民援助请求的机器人。部分资金用于国防，包括致命的自主武器和军用机器人。2025年1月，第14179号行政命令制定了“人工智能行动计划”，以加速这些技术的创新和部署。[需要非主要来源]

## 另请参阅

+ 人工神经网络的历史
+ 知识表示和推理的历史
+ 自然语言处理的历史
+ 人工智能概述
+ 人工智能的进展
+ 人工智能时间线
+ 机器学习时间线

## 本文翻译自英语Wikipedia原文

+ [History of artificial intelligence](https://en.wikipedia.org/wiki/History_of_artificial_intelligence)